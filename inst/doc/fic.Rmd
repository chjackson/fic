---
title: "Theory of focused model comparison"
date: "`r Sys.Date()`"
author: Chris Jackson <chris.jackson@mrc-bsu.cam.ac.uk>
output: 
  html_document: 
    includes:
      before_body: fic.sty  
  code_folding: show
vignette: >
 %\VignetteIndexEntry{Theory of focused model comparison}
 %\VignetteEngine{knitr::rmarkdown}
 %\VignetteDepends{fic,ggplot2}
 %\VignetteEncoding{UTF-8}
bibliography: fic.bib
---

This is a brief tutorial in the "focused" model comparison methods developed by Claeskens and Hjort.

These can be implemented in the `fic` R package. 

The method originates from the paper by @fic , and is developed further in the book by @claeskens:hjort:book , and a series of related papers. 

# Some familiar model comparison methods 

For comparing a set of models fitted by maximum likelihood, it is common to rank the models according to some "criterion".  For example, Akaike's information criterion (AIC, @aic) takes the form 

$$ -2\log \ell(\hat\theta ; \mathbf{x}) + 2p $$
where $\ell(\hat\theta ; \mathbf{x})$ is the maximised likelihood for the model fitted to the dataset $\mathbf{x}$, the likelihood is maximised at parameters $\hat\theta$, and $p$ is the number of parameters. 

The Bayesian information criterion (BIC, @schwarz) is

$$ -2\log \ell(\hat\theta ; \mathbf{x}) + p\log(n) $$

These two criteria are based on very different principles.  Thus they often rank models differently.  

The AIC is designed to choose the model with the best predictive ability, thus it tends to favour bigger models as the sample size increases.   

BIC is an approximation to Bayesian model comparison by Bayes factors, and selects the model with the highest posterior probability under an implicit weak prior (with an amount of information equivalent to one observation, see @kass:wasserman ).  If there is a "true" model, the BIC will select it "consistently" as the sample size increases.  In many situations there may not be a true model, and collecting more data will uncover more complexity in the process generating the data - in which case AIC may be more suitable. 

See e.g. @burnham:anderson:book, @claeskens:hjort:book for more theory behind these criteria.

However both of these methods select one "best fitting" model for a given dataset.  But that might not always be appropriate. Different models may be better for different purposes.  This is the idea behind "focused" model comparison. 


# Focused model comparison: principles.

Suppose the range of models we are willing to use is bounded by 

* a *wide model*, in which all models we would use are nested

* a *narrow model*, the smallest model we are willing to use

Suppose also that the purpose of the model is to estimate some *focus* quantity, which could be any function of the basic parameters 

$$\mu = g(\btheta, \bgamma)$$

In focused model comparison, we prefer models which give better estimates of $\mu$.  A typical way to define "best" is by the *mean square error*.   The mean square error of the estimate $\hat\mu_S$ of $\mu$ under a submodel $S$ of the wide model is 

$$E(\hat\mu_s - \mu)^2$$ 

where $\mu$ is the true value of $\mu$.  This expectation is calculated under the assumption that the data are generated from the wide model.   While we believe the wide model is the most realistic, we also accept that there may not be enough data to give sufficiently precise estimates of $\mu$.  Therefore we are willing to accept some bias in this estimate, in return for a smaller variance, by selecting a smaller model than the wide model.  The submodel $S$ with the lowest mean square error is the one which makes the optimal trade-off between bias and variance. 


# Focused information criterion: formula

The expected squared error under model $S$ can be decomposed as a sum of the squared bias $B^2$ and the variance $V$. 

\begin{aligned}
MSE = E\left\{(\hat\mu_S - \mu\right)^2\}  & = \left\{E(\hat\mu_S)- \mu\right\}^2 + E\left\{(\hat\mu_S -  E(\hat\mu_S))^2\right\} \\
    & = B^2 + V
\end{aligned}

Estimators for these quantities are constructed by @fic under an asymptotic framework in which the data are assumed to be generated from the wide model, but reparameterised so that $\bgamma = \gamma_0 + \bdelta / \sqrt{n}$.  Thus as the sample size increases, we aim to detect more subtle departures from the narrow model. 

## Bias 

An obvious estimator for the bias $B$ is 

\[ \hat{B} = \hat{\mu_S} - \hat{\mu_W} \]

where $\hat\mu_W$ is the estimate of the focus quantity under the wide model, which is assumed to be unbiased. 
However, @fic derive a more accurate estimator for the *squared* bias as 

$$\hat{B^2} = ( \psi_{full} - \psi_S )^2 / n$$, 

where $\psi_{full} = \hat\omega^T\hat\delta, \psi_S = \hat\omega^T (\pi^T Q_S \pi  Q^{-1} )\hat\delta$, $\hat\delta = \hat\gamma\sqrt{n}$, $\hat\gamma$ is the estimate of $\gamma$ under the wide model, 
$\hat\omega = J_{10}J_{00}^{-1}\frac{d\mu}{d\theta} - \frac{d\mu}{d\gamma}$, 
$Q_S = (\pi Q^{-1} \pi^T)^{-1}$, $Q^{-1} = J_{11}$, $J$ is the information matrix (inverse covariance) under the wide model divided by $n$, and subscripts $0$ and $1$ select the rows and columns forming the submatrices of $J$
corresponding to parameters $\btheta$ and $\bgamma$ respectively, and $\pi$ is the projection matrix that selects entries of submodel $S$.  TODO tidy this list, clarify. can we get rid of the $n$? 


##Â Variance 

The estimator for the variance of $\hat{\mu}_S$ under the wide model, derived by @fic, is 

\[V = (\hat{\tau}^2 + \hat{\omega}^T Q_0 \hat{\omega}) / n\] 

where $\hat{\tau}^2 /n$ is the variance of $\hat{\mu}_S$ under submodel $S$, and the additional term $(\hat{\omega}^T Q_0 \hat{\omega}) / n$ is the increase in variance resulting from the fact that model $S$ is misspecified.  $\hat\tau^2 = \frac{d\mu}{d\theta}^T  J_{00}^{-1} \frac{d\mu}{d\theta}$, and $Q_{0} = \pi^T Q_S \pi$.


## Components of the MSE

Therefore in order to calculate the MSE, we just need to know

* the estimates $\hat{\btheta}_W$ and $\hat{\bgamma}_W$ under the wide model 

* the information matrix $J$ or covariance matrix of these estimates 

* the focus function $\mu(\btheta,\bgamma)$ and its derivatives, evaluated at $\hat{\btheta}_W,\hat{\bgamma}_W$.  
* the definition of which parameters are included in submodel $S$

This is what the function `fic` from the `fic` package does . LEAD INTO ...


# Using the fic package

*** 

### References
